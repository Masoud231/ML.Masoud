import streamlit as st
import numpy as np
import joblib
import os
import cv2

st.set_page_config(page_title="Eye State Detection", layout="wide")

st.title("ğŸ‘ï¸ Eye State Detection System")
st.write("Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ÙˆØ¶Ø¹ÛŒØª Ú†Ø´Ù… Ø¨Ø§ Ø¯Ùˆ Ø±ÙˆØ´: EEG Ùˆ Ø¯ÙˆØ±Ø¨ÛŒÙ† (Ø¨Ø¯ÙˆÙ† mediapipe)")

tabs = st.tabs(["ğŸ”µ EEG Prediction", "ğŸŸ¢ Camera Eye Detection"])

# ============================================================
# TAB 1 â€” EEG MODEL
# ============================================================
with tabs[0]:
    st.header("Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ÙˆØ¶Ø¹ÛŒØª Ú†Ø´Ù… Ø¨Ø§ EEG")

    base = os.path.dirname(os.path.abspath(__file__))
    model_path = os.path.join(base, "eye_state_model.pkl")
    scaler_path = os.path.join(base, "scaler.pkl")

    if not os.path.exists(model_path) or not os.path.exists(scaler_path):
        st.error("âŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø¯Ù„ EEG Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯Ù†Ø¯. Ù„Ø·ÙØ§Ù‹ eye_state_model.pkl Ùˆ scaler.pkl Ø±Ø§ Ø¯Ø± Ø±ÛŒÙ¾Ùˆ Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯.")
        st.stop()

    model = joblib.load(model_path)
    scaler = joblib.load(scaler_path)

    st.subheader("ÙˆØ±ÙˆØ¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ (14 Ù…Ù‚Ø¯Ø§Ø± EEG)")

    if st.button("ğŸ”„ ØªÙˆÙ„ÛŒØ¯ Ù†Ù…ÙˆÙ†Ù‡ EEG ØªØµØ§Ø¯ÙÛŒ"):
        random_sample = np.random.normal(0, 1, 14)
        for i in range(14):
            st.session_state[f"f{i}"] = float(random_sample[i])

    features = []
    for i in range(14):
        val = st.number_input(
            f"Feature {i+1}",
            value=st.session_state.get(f"f{i}", 0.0),
            format="%.4f"
        )
        features.append(val)

    if st.button("ğŸ” Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ EEG"):
        sample = np.array([features])
        sample_scaled = scaler.transform(sample)
        prediction = model.predict(sample_scaled)[0]

        if prediction == 0:
            st.error("ğŸ‘ï¸â€ğŸ—¨ï¸ Ù†ØªÛŒØ¬Ù‡: Ú†Ø´Ù… Ø¨Ø³ØªÙ‡")
        else:
            st.success("ğŸ‘ï¸ Ù†ØªÛŒØ¬Ù‡: Ú†Ø´Ù… Ø¨Ø§Ø²")


# ============================================================
# TAB 2 â€” CAMERA DETECTION (NO MEDIAPIPE)
# ============================================================
with tabs[1]:
    st.header("ØªØ´Ø®ÛŒØµ Ø¨Ø§Ø²/Ø¨Ø³ØªÙ‡ Ø¨ÙˆØ¯Ù† Ú†Ø´Ù… Ø¨Ø§ Ø¯ÙˆØ±Ø¨ÛŒÙ† (Ø¨Ø¯ÙˆÙ† mediapipe)")

    run = st.checkbox("ÙØ¹Ø§Ù„ Ú©Ø±Ø¯Ù† Ø¯ÙˆØ±Ø¨ÛŒÙ†")

    # Load Haarcascade
    eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_eye.xml")

    FRAME_WINDOW = st.image([])

    cap = cv2.VideoCapture(0)

    while run:
        ret, frame = cap.read()
        if not ret:
            break

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        eyes = eye_cascade.detectMultiScale(gray, 1.3, 5)

        if len(eyes) == 0:
            status = "Ú†Ø´Ù… Ø¨Ø³ØªÙ‡"
            color = (0, 0, 255)
        else:
            status = "Ú†Ø´Ù… Ø¨Ø§Ø²"
            color = (0, 255, 0)

        cv2.putText(frame, status, (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 3)

        FRAME_WINDOW.image(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))

    cap.release()
