import streamlit as st
import numpy as np
import joblib
import os
import cv2
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase

st.set_page_config(page_title="Eye State Detection", layout="wide")

st.title("ğŸ‘ï¸ Eye State Detection System (Web Version)")
st.write("Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ÙˆØ¶Ø¹ÛŒØª Ú†Ø´Ù… Ø¨Ø§ EEG Ùˆ ØªØ´Ø®ÛŒØµ Ú†Ø´Ù… Ø¨Ø§ Ø¯ÙˆØ±Ø¨ÛŒÙ† (Ù†Ø³Ø®Ù‡ ØªØ­Øª ÙˆØ¨)")

tabs = st.tabs(["ğŸ”µ EEG Prediction", "ğŸŸ¢ Camera Eye Detection"])

# ============================================================
# TAB 1 â€” EEG MODEL
# ============================================================
with tabs[0]:
    st.header("Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ÙˆØ¶Ø¹ÛŒØª Ú†Ø´Ù… Ø¨Ø§ EEG")

    base = os.path.dirname(os.path.abspath(__file__))
    model_path = os.path.join(base, "eye_state_model.pkl")
    scaler_path = os.path.join(base, "scaler.pkl")

    if not os.path.exists(model_path) or not os.path.exists(scaler_path):
        st.error("âŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø¯Ù„ EEG Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯Ù†Ø¯.")
        st.stop()

    model = joblib.load(model_path)
    scaler = joblib.load(scaler_path)

    st.subheader("ÙˆØ±ÙˆØ¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ (14 Ù…Ù‚Ø¯Ø§Ø± EEG)")

    if st.button("ğŸ”„ ØªÙˆÙ„ÛŒØ¯ Ù†Ù…ÙˆÙ†Ù‡ EEG ØªØµØ§Ø¯ÙÛŒ"):
        random_sample = np.random.normal(0, 1, 14)
        for i in range(14):
            st.session_state[f"f{i}"] = float(random_sample[i])

    features = []
    for i in range(14):
        val = st.number_input(
            f"Feature {i+1}",
            value=st.session_state.get(f"f{i}", 0.0),
            format="%.4f"
        )
        features.append(val)

    if st.button("ğŸ” Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ EEG"):
        sample = np.array([features])
        sample_scaled = scaler.transform(sample)
        prediction = model.predict(sample_scaled)[0]

        if prediction == 0:
            st.success("Eyes Open")
        else:
            st.error("Eyes Closed")


# ============================================================
# TAB 2 â€” CAMERA DETECTION (WEBRTC)
# ============================================================
class EyeDetector(VideoTransformerBase):
    def __init__(self):
        self.eye_cascade = cv2.CascadeClassifier("haarcascade_eye.xml")

    def transform(self, frame):
        img = frame.to_ndarray(format="bgr24")
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        eyes = self.eye_cascade.detectMultiScale(gray, 1.3, 5)

        if len(eyes) == 0:
            status = "Eyes Closed"
            color = (0, 0, 255)
        else:
            status = "Eyes Open"
            color = (0, 255, 0)

        cv2.putText(img, status, (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 3)
        return img

with tabs[1]:
    st.header("Camera Eye Detection (WebRTC)")
    webrtc_streamer(
        key="eye-detection",
        video_transformer_factory=EyeDetector,
        media_stream_constraints={"video": True, "audio": False},
    )
